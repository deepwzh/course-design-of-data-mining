{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "# from sklearn.cross_validation import KFold\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sample = pd.read_csv('dataset/model.csv')\n",
    "model_sample.set_index('user_id',inplace=True)\n",
    "label = model_sample[['y']]\n",
    "model_sample = model_sample.drop('y',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_middle(data):\n",
    "    model_sample_strong_feature = data.copy()\n",
    "    # 将身份信息以及财产信息进行编码\n",
    "    first_strong_features = ['x_003','x_004','x_005','x_006','x_007','x_008','x_009','x_010','x_011','x_012','x_013','x_014','x_015','x_016','x_017','x_018','x_019']\n",
    "    res = 0\n",
    "    for i in range(len(first_strong_features)):\n",
    "        res += 2 ** i * data[first_strong_features[i]]\n",
    "\n",
    "    model_sample_strong_feature['x_1_strong'] = res \n",
    "    # 借记卡的比例特征\n",
    "    model_sample_strong_feature['x_022/x_020'] = data['x_022'] / (data['x_020'] + 1e-10)\n",
    "    model_sample_strong_feature['x_023/x_020'] = data['x_023'] / (data['x_020'] + 1e-10)\n",
    "    model_sample_strong_feature['x_024/x_020'] = data['x_024'] /  (data['x_020'] + 1e-10)\n",
    "    model_sample_strong_feature['x_025/x_020'] = data['x_025'] /  (data['x_020']+ 1e-10)\n",
    "    model_sample_strong_feature['x_026/x_020'] = data['x_026'] /  (data['x_020'] + 1e-10)\n",
    "    \n",
    "    # 贷记卡的比例特征\n",
    "    model_sample_strong_feature['x_028/x_021'] = data['x_028'] / (data['x_021'] + 1e-10)\n",
    "    model_sample_strong_feature['x_029/x_021'] = data['x_029'] / (data['x_021'] + 1e-10)\n",
    "    model_sample_strong_feature['x_030/x_021'] = data['x_030'] /  (data['x_021'] + 1e-10)\n",
    "    model_sample_strong_feature['x_031/x_021'] = data['x_031'] /  (data['x_021'] + 1e-10)\n",
    "    model_sample_strong_feature['x_032/x_021'] = data['x_032'] /  (data['x_021'] + 1e-10)\n",
    "    \n",
    "    # 银行卡的比例特征\n",
    "    model_sample_strong_feature['all_cards'] = (data['x_034'] +  data['x_035'] + data['x_036'] + data['x_037'] + data['x_038'] + data['x_039'] + data['x_040']  ).values\n",
    "\n",
    "    model_sample_strong_feature['x_034/all_cards'] = data['x_034'] / (model_sample_strong_feature['all_cards'] + 1e-10)\n",
    "    model_sample_strong_feature['x_035/all_cards'] = data['x_035'] / (model_sample_strong_feature['all_cards'] + 1e-10)\n",
    "    model_sample_strong_feature['x_036/all_cards'] = data['x_036'] /  (model_sample_strong_feature['all_cards'] + 1e-10)\n",
    "    model_sample_strong_feature['x_037/all_cards'] = data['x_037'] /  (model_sample_strong_feature['all_cards'] + 1e-10)\n",
    "    model_sample_strong_feature['x_038/all_cards'] = data['x_038'] /  (model_sample_strong_feature['all_cards'] + 1e-10)\n",
    "    model_sample_strong_feature['x_039/all_cards'] = data['x_039'] /  (model_sample_strong_feature['all_cards'] + 1e-10)\n",
    "    model_sample_strong_feature['x_040/all_cards'] = data['x_040'] /  (model_sample_strong_feature['all_cards'] + 1e-10)\n",
    "   \n",
    "    # 标准差还原\n",
    "    model_sample_strong_feature['x_043/x_044'] = data['x_043'] / (data['x_044'] + 1e-10)\n",
    "    model_sample_strong_feature['x_046/x_047'] = data['x_046'] / (data['x_047'] + 1e-10)\n",
    "    model_sample_strong_feature['x_050/x_051'] = data['x_050'] / (data['x_051'] + 1e-10)\n",
    "    model_sample_strong_feature['x_053/x_054'] = data['x_053'] / (data['x_054'] + 1e-10)\n",
    "    model_sample_strong_feature['x_057/x_058'] = data['x_057'] / (data['x_058'] + 1e-10)\n",
    "    model_sample_strong_feature['x_060/x_061'] = data['x_060'] / (data['x_061'] + 1e-10)\n",
    "    model_sample_strong_feature['x_076/x_077'] = data['x_076'] / (data['x_077'] + 1e-10)\n",
    "    model_sample_strong_feature['x_079/x_080'] = data['x_079'] / (data['x_080'] + 1e-10)\n",
    "    model_sample_strong_feature['x_083/x_084'] = data['x_083'] / (data['x_084'] + 1e-10)\n",
    "    model_sample_strong_feature['x_086/x_087'] = data['x_086'] / (data['x_087'] + 1e-10)\n",
    "    model_sample_strong_feature['x_090/x_091'] = data['x_090'] / (data['x_091'] + 1e-10)\n",
    "    model_sample_strong_feature['x_094/x_095'] = data['x_094'] / (data['x_095'] + 1e-10)\n",
    "    model_sample_strong_feature['x_098/x_099'] = data['x_098'] / (data['x_099'] + 1e-10)\n",
    "    model_sample_strong_feature['x_123/x_124'] = data['x_123'] / (data['x_124'] + 1e-10)\n",
    "    model_sample_strong_feature['x_126/x_127'] = data['x_126'] / (data['x_127'] + 1e-10)\n",
    "\n",
    "    \n",
    "    # 每张卡（信用or其他）交易金额等；每笔（异地每笔）交易金额等；每笔还款金额等；每笔商旅，保险，家装，金融等的均值特征；每个月的平均交易笔数；其他有意义的均值特征\n",
    "    \n",
    "    model_sample_strong_feature['x_045/x_41'] = data['x_045'] / (data['x_041'] + 1e-10)\n",
    "    model_sample_strong_feature['x_052/x_48'] = data['x_052'] / (data['x_048'] + 1e-10)\n",
    "    model_sample_strong_feature['x_059/x_55'] = data['x_059'] / (data['x_055'] + 1e-10) \n",
    "    model_sample_strong_feature['x_064/x_062'] = data['x_064'] / (data['x_062'] + 1e-10)\n",
    "    model_sample_strong_feature['x_067/x_065'] = data['x_067'] / (data['x_065'] + 1e-10)  \n",
    "    model_sample_strong_feature['x_070/x_068'] = data['x_070'] / (data['x_068'] + 1e-10)\n",
    "    model_sample_strong_feature['x_073/x_071'] = data['x_073'] / (data['x_071'] + 1e-10) \n",
    "    model_sample_strong_feature['x_078/x_074'] = data['x_078'] / (data['x_074'] + 1e-10)  \n",
    "    model_sample_strong_feature['x_085/x_081'] = data['x_085'] / (data['x_081'] + 1e-10) \n",
    "    model_sample_strong_feature['x_100/x_101'] = data['x_100'] / (data['x_101'] + 1e-10)\n",
    "    model_sample_strong_feature['x_102/x_103'] = data['x_102'] / (data['x_103'] + 1e-10) \n",
    "    model_sample_strong_feature['x_108/x_105'] = data['x_108'] / (data['x_105'] + 1e-10)\n",
    "    model_sample_strong_feature['x_104/x_102'] = data['x_104'] / (data['x_102'] + 1e-10) \n",
    "    model_sample_strong_feature['x_109/x_110'] = data['x_109'] / (data['x_110'] + 1e-10)\n",
    "    model_sample_strong_feature['x_111/x_109'] = data['x_111'] / (data['x_109'] + 1e-10) \n",
    "    model_sample_strong_feature['x_112/x_113'] = data['x_112'] / (data['x_113'] + 1e-10)\n",
    "    model_sample_strong_feature['x_114/x_112'] = data['x_114'] / (data['x_112'] + 1e-10) \n",
    "    model_sample_strong_feature['x_115/x_116'] = data['x_115'] / (data['x_116'] + 1e-10)\n",
    "    model_sample_strong_feature['x_117/x_115'] = data['x_117'] / (data['x_115'] + 1e-10)  \n",
    "    model_sample_strong_feature['x_118/x_119'] = data['x_118'] / (data['x_119'] + 1e-10)\n",
    "    model_sample_strong_feature['x_120/x_118'] = data['x_120'] / (data['x_118'] + 1e-10) \n",
    "    model_sample_strong_feature['x_125/x_121'] = data['x_125'] / (data['x_121'] + 1e-10) \n",
    "    model_sample_strong_feature['x_128/x_129'] = data['x_128'] / (data['x_129'] + 1e-10)\n",
    "    model_sample_strong_feature['x_130/x_128'] = data['x_130'] / (data['x_128'] + 1e-10)\n",
    "\n",
    "    # 每笔放款金额，每个机构的放款笔数，每个机构的放款金额\n",
    "    model_sample_strong_feature['x_133/x_134'] = data['x_133'] / (data['x_134'] + 1e-10)\n",
    "    model_sample_strong_feature['x_133/x_132'] = data['x_133'] / (data['x_132'] + 1e-10)\n",
    "    model_sample_strong_feature['x_134/x_132'] = data['x_134'] / (data['x_132'] + 1e-10) \n",
    "    model_sample_strong_feature['x_138/x_139'] = data['x_138'] / (data['x_139'] + 1e-10)\n",
    "    model_sample_strong_feature['x_138/x_137'] = data['x_138'] / (data['x_137'] + 1e-10)\n",
    "    model_sample_strong_feature['x_139/x_137'] = data['x_139'] / (data['x_137'] + 1e-10) \n",
    "    model_sample_strong_feature['x_143/x_142'] = data['x_143'] / (data['x_142'] + 1e-10)\n",
    "    model_sample_strong_feature['x_143/x_144'] = data['x_143'] / (data['x_144'] + 1e-10)\n",
    "    model_sample_strong_feature['x_144/x_142'] = data['x_144'] / (data['x_142'] + 1e-10)\n",
    "\n",
    "    # 每个机构的放款均值,失败还款笔数占比\n",
    "    model_sample_strong_feature['x_151/x_149'] = data['x_151'] / (data['x_149'] + 1e-10)\n",
    "    model_sample_strong_feature['x_152/x_149'] = data['x_152'] / (data['x_149'] + 1e-10)\n",
    "    model_sample_strong_feature['x_152/x_151'] = data['x_152'] / (data['x_151'] + 1e-10)\n",
    "    model_sample_strong_feature['x_154/x_153'] = data['x_154'] / (data['x_153'] + 1e-10)\n",
    "    model_sample_strong_feature['x_156/x_153'] = data['x_156'] / (data['x_153'] + 1e-10)\n",
    "    model_sample_strong_feature['x_157/x_153'] = data['x_157'] / (data['x_153'] + 1e-10)\n",
    "    model_sample_strong_feature['x_158/x_153'] = data['x_158'] / (data['x_153'] + 1e-10)\n",
    "    model_sample_strong_feature['x_159/x_153'] = data['x_159'] / (data['x_153'] + 1e-10)  \n",
    "    model_sample_strong_feature['x_154/x_155'] = data['x_154'] / (data['x_155'] + 1e-10)  \n",
    "\n",
    "    model_sample_strong_feature['x_164/x_162'] = data['x_164'] / (data['x_162'] + 1e-10)\n",
    "    model_sample_strong_feature['x_165/x_162'] = data['x_165'] / (data['x_162'] + 1e-10)\n",
    "    model_sample_strong_feature['x_165/x_164'] = data['x_165'] / (data['x_164'] + 1e-10)\n",
    "    model_sample_strong_feature['x_167/x_166'] = data['x_167'] / (data['x_166'] + 1e-10)\n",
    "    model_sample_strong_feature['x_169/x_166'] = data['x_169'] / (data['x_166'] + 1e-10)\n",
    "    model_sample_strong_feature['x_170/x_166'] = data['x_170'] / (data['x_166'] + 1e-10)\n",
    "    model_sample_strong_feature['x_171/x_166'] = data['x_171'] / (data['x_166'] + 1e-10)\n",
    "    model_sample_strong_feature['x_180/x_181'] = data['x_180'] / (data['x_181'] + 1e-10) \n",
    "    model_sample_strong_feature['x_167/x_168'] = data['x_167'] / (data['x_168'] + 1e-10) \n",
    "    model_sample_strong_feature['x_172/x_167'] = data['x_172'] / (data['x_167'] + 1e-10)  \n",
    "\n",
    "    model_sample_strong_feature['x_177/x_175'] = data['x_177'] / (data['x_175'] + 1e-10)\n",
    "    model_sample_strong_feature['x_178/x_175'] = data['x_178'] / (data['x_175'] + 1e-10)\n",
    "    model_sample_strong_feature['x_178/x_177'] = data['x_178'] / (data['x_177'] + 1e-10)\n",
    "    model_sample_strong_feature['x_180/x_179'] = data['x_180'] / (data['x_179'] + 1e-10)\n",
    "    model_sample_strong_feature['x_182/x_179'] = data['x_182'] / (data['x_179'] + 1e-10)\n",
    "    model_sample_strong_feature['x_183/x_179'] = data['x_183'] / (data['x_179'] + 1e-10)\n",
    "    model_sample_strong_feature['x_184/x_179'] = data['x_184'] / (data['x_179'] + 1e-10)\n",
    "    model_sample_strong_feature['x_180/x_181'] = data['x_180'] / (data['x_181'] + 1e-10) \n",
    "    model_sample_strong_feature['x_185/x_180'] = data['x_185'] / (data['x_180'] + 1e-10)\n",
    " \n",
    "    # 90天与30天的申请贷款机构的趋势，180天与90天的申请贷款机构的趋势，180天与30天的申请贷款机构的趋势；90天与30天的成功申请贷款机构的趋势，180天与90天的成功申请贷款机构的趋势，180天；\n",
    "    # 30天的成功申请贷款机构的趋势；90天与30天的申请贷款笔数的趋势，180天与90天的申请贷款笔数的趋势，180天与30天的申请贷款笔数的趋势90天的申请贷款笔数的趋势\n",
    "    model_sample_strong_feature['x_189/x_188'] = data['x_189'] / (data['x_188'] + 1e-10)\n",
    "    model_sample_strong_feature['x_191/x_190'] = data['x_191'] / (data['x_190'] + 1e-10)\n",
    "    model_sample_strong_feature['x_193/x_192'] = data['x_193'] / (data['x_192'] + 1e-10)\n",
    "    model_sample_strong_feature['x_195/x_194'] = data['x_195'] / (data['x_194'] + 1e-10)\n",
    "    model_sample_strong_feature['x_197/x_196'] = data['x_197'] / (data['x_196'] + 1e-10)\n",
    "    model_sample_strong_feature['x_199/x_198'] = data['x_199'] / (data['x_198'] + 1e-10)\n",
    "    model_sample_strong_feature['x_196/x_188'] = data['x_196'] / (data['x_188'] + 1e-10)\n",
    "    model_sample_strong_feature['x_192/x_188'] = data['x_192'] / (data['x_188'] + 1e-10)\n",
    "                                                                   \n",
    "    model_sample_strong_feature = model_sample_strong_feature.fillna(-999)\n",
    "    return model_sample_strong_feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'descibe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-1b6eb35b9147>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_features_middle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescibe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\wzh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   3612\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3613\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3614\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3616\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'descibe'"
     ]
    }
   ],
   "source": [
    "get_features_middle(model_sample).descibe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(y_pred, y_true):\n",
    "    acc_ = accuracy_score(y_true=y_true,y_pred=y_pred)\n",
    "    TP = np.sum(((y_pred == 1) & (y_true == 1))) \n",
    "    precision = TP / np.sum(y_pred)\n",
    "    recall = TP / np.sum(y_true)\n",
    "    print('TP: ',TP,'/', np.sum(y_true), 'all ',np.sum(y_pred), ' accuracy: ',acc_, ' precision: ',precision, ' recall: ',recall, ' F_score: ', 2 * precision * recall / (precision + recall),fbeta_score(y_true=y_true,y_pred=y_pred,beta=1) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def N_Fold_Predict( train_fea , train_y,  test_fea, cv_ = 5):\n",
    "\n",
    "    ###########################################################\n",
    "    train_fea = train_fea.fillna(-1)\n",
    "    test_fea = test_fea.fillna(-1)\n",
    "\n",
    "    features_col = [c for c in train_fea.columns if c not in ['user_id','y']]\n",
    "    X = train_fea[features_col] \n",
    "    X_pred = test_fea[features_col]\n",
    "    \n",
    "    pred_out_lgb = 0\n",
    "    pred_out_gbdt = 0\n",
    "    pred_out_rf = 0\n",
    "    \n",
    "    for cv in range(cv_):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, train_y, test_size=0.25, random_state=np.random.randint(1000)) \n",
    "        # create dataset for lightgbm\n",
    "        lgb_train = lgb.Dataset(X_train, y_train)\n",
    "        lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "        # specify your configurations as a dict\n",
    "        params = {\n",
    "            'task':'train',\n",
    "            'boosting_type':'gbdt',\n",
    "            'num_leaves': 31,\n",
    "            'objective': 'binary', \n",
    "            'learning_rate': 0.05, \n",
    "            'bagging_freq': 2, \n",
    "            'max_bin':256,\n",
    "            'num_threads': 32\n",
    "        } \n",
    "\n",
    "        # train\n",
    "        gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    verbose_eval= 0,\n",
    "                    num_boost_round=10000,\n",
    "                    valid_sets=lgb_eval,\n",
    "                    early_stopping_rounds=100)\n",
    "\n",
    "        lgb_pred = gbm.predict(X_pred, num_iteration=gbm.best_iteration)\n",
    "        \n",
    "        \n",
    "        gbdt = GradientBoostingClassifier(n_estimators=250,learning_rate=0.01,max_depth=6,min_samples_leaf=5,min_samples_split=5)\n",
    "        gbdt.fit(X_train, y_train)\n",
    "        gbdt_pred = gbdt.predict_proba(X_pred)[:,1] \n",
    "        \n",
    "        \n",
    "        rf = RandomForestClassifier(n_estimators=500,max_depth=6,min_samples_leaf=5,min_samples_split=5)\n",
    "        rf.fit(X_train, y_train)\n",
    "        rf_pred = rf.predict_proba(X_pred)[:,1]  \n",
    "        \n",
    "        if cv == 0:\n",
    "            pred_out_lgb = lgb_pred\n",
    "            pred_out_gbdt = gbdt_pred\n",
    "            pred_out_rf = rf_pred\n",
    "        else:\n",
    "            pred_out_lgb += lgb_pred\n",
    "            pred_out_gbdt += gbdt_pred\n",
    "            pred_out_rf += rf_pred\n",
    "            \n",
    "    pred_out_lgb = pred_out_lgb * 1.0 / cv_\n",
    "    pred_out_gbdt = pred_out_gbdt * 1.0 / cv_\n",
    "    pred_out_rf = pred_out_rf * 1.0 / cv_\n",
    "    return pred_out_lgb, pred_out_gbdt, pred_out_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_final(data):\n",
    "    model_sample_strong_feature = data.copy()\n",
    "    \n",
    "    first_strong_features = ['x_003','x_004','x_005','x_006','x_007','x_008','x_009','x_010','x_011','x_012','x_013','x_014','x_015','x_016','x_017','x_018','x_019']\n",
    "\n",
    "    res = 0\n",
    "    for i in range(len(first_strong_features)):\n",
    "        res += 2 ** i * data[first_strong_features[i]] \n",
    "    model_sample_strong_feature['x_1_strong'] = res\n",
    "\n",
    "    model_sample_strong_feature['x_022/x_020'] = data['x_022'] / (data['x_020'] + 1e-10)\n",
    "    model_sample_strong_feature['x_023/x_020'] = data['x_023'] / (data['x_020'] + 1e-10)\n",
    "    model_sample_strong_feature['x_024/x_020'] = data['x_024'] /  (data['x_020'] + 1e-10)\n",
    "    model_sample_strong_feature['x_025/x_020'] = data['x_025'] /  (data['x_020'] + 1e-10)\n",
    "    model_sample_strong_feature['x_026/x_020'] = data['x_026'] /  (data['x_020'] + 1e-10)\n",
    "    \n",
    "    \n",
    "    model_sample_strong_feature['x_028/x_021'] = data['x_028'] / (data['x_021'] + 1e-10)\n",
    "    model_sample_strong_feature['x_029/x_021'] = data['x_029'] / (data['x_021'] + 1e-10)\n",
    "    model_sample_strong_feature['x_030/x_021'] = data['x_030'] /  (data['x_021'] + 1e-10)\n",
    "    model_sample_strong_feature['x_031/x_021'] = data['x_031'] /  (data['x_021'] + 1e-10)\n",
    "    model_sample_strong_feature['x_032/x_021'] = data['x_032'] /  (data['x_021'] + 1e-10)\n",
    "    \n",
    "    \n",
    "    model_sample_strong_feature['all_cards'] = (data['x_034']  + data['x_035'] + data['x_036'] + data['x_037'] + data['x_038'] + data['x_039'] + data['x_040']).values\n",
    "\n",
    "    model_sample_strong_feature['x_034/all_cards'] = data['x_034'] / (model_sample_strong_feature['all_cards'] + 1e-10)\n",
    "    model_sample_strong_feature['x_035/all_cards'] = data['x_035'] / (model_sample_strong_feature['all_cards'] + 1e-10)\n",
    "    model_sample_strong_feature['x_036/all_cards'] = data['x_036'] /  (model_sample_strong_feature['all_cards'] + 1e-10)\n",
    "    model_sample_strong_feature['x_037/all_cards'] = data['x_037'] /  (model_sample_strong_feature['all_cards'] + 1e-10)\n",
    "    model_sample_strong_feature['x_038/all_cards'] = data['x_038'] /  (model_sample_strong_feature['all_cards'] + 1e-10)\n",
    "    model_sample_strong_feature['x_039/all_cards'] = data['x_039'] /  (model_sample_strong_feature['all_cards'] + 1e-10)\n",
    "    model_sample_strong_feature['x_040/all_cards'] = data['x_040'] /  (model_sample_strong_feature['all_cards'] + 1e-10)\n",
    "\n",
    "    model_sample_strong_feature['x_027/x_033'] = data['x_027'] -  (data['x_033'] + 1e-10)\n",
    "    \n",
    "    \n",
    "    \n",
    "    model_sample_strong_feature['x_043/x_044'] = data['x_043'] / (data['x_044'] + 1e-10)\n",
    "    model_sample_strong_feature['x_046/x_047'] = data['x_046'] / (data['x_047'] + 1e-10)\n",
    "    model_sample_strong_feature['x_050/x_051'] = data['x_050'] / (data['x_051'] + 1e-10)\n",
    "    model_sample_strong_feature['x_053/x_054'] = data['x_053'] / (data['x_054'] + 1e-10)\n",
    "    model_sample_strong_feature['x_057/x_058'] = data['x_057'] / (data['x_058'] + 1e-10)\n",
    "    model_sample_strong_feature['x_060/x_061'] = data['x_060'] / (data['x_061'] + 1e-10)\n",
    "    model_sample_strong_feature['x_076/x_077'] = data['x_076'] / (data['x_077'] + 1e-10)\n",
    "    model_sample_strong_feature['x_079/x_080'] = data['x_079'] / (data['x_080'] + 1e-10)\n",
    "    model_sample_strong_feature['x_083/x_084'] = data['x_083'] / (data['x_084'] + 1e-10) \n",
    "    model_sample_strong_feature['x_086/x_087'] = data['x_086'] / (data['x_087'] + 1e-10)\n",
    "    model_sample_strong_feature['x_090/x_091'] = data['x_090'] / (data['x_091'] + 1e-10)\n",
    "    model_sample_strong_feature['x_094/x_095'] = data['x_094'] / (data['x_095'] + 1e-10)\n",
    "    model_sample_strong_feature['x_098/x_099'] = data['x_098'] / (data['x_099'] + 1e-10) \n",
    "    model_sample_strong_feature['x_123/x_124'] = data['x_123'] / (data['x_124'] + 1e-10)\n",
    "    model_sample_strong_feature['x_126/x_127'] = data['x_126'] / (data['x_127'] + 1e-10) \n",
    "    \n",
    "    \n",
    "    model_sample_strong_feature['x_064/x_063'] = data['x_064'] / (data['x_063'] + 1e-10)\n",
    "    model_sample_strong_feature['x_067/x_066'] = data['x_067'] / (data['x_066'] + 1e-10)\n",
    "    model_sample_strong_feature['x_070/x_069'] = data['x_070'] / (data['x_069'] + 1e-10)\n",
    "    model_sample_strong_feature['x_073/x_072'] = data['x_073'] / (data['x_072'] + 1e-10)\n",
    "    \n",
    "    model_sample_strong_feature['x_059/x_55'] = data['x_059'] / (data['x_055'] + 1e-10)\n",
    "    model_sample_strong_feature['x_067/x_065'] = data['x_067'] / (data['x_065'] + 1e-10)\n",
    "    model_sample_strong_feature['x_070/x_068'] = data['x_070'] / (data['x_068'] + 1e-10)\n",
    "    model_sample_strong_feature['x_073/x_071'] = data['x_073'] / (data['x_071'] + 1e-10)\n",
    "    model_sample_strong_feature['x_078/x_074'] = data['x_078'] / (data['x_074'] + 1e-10)\n",
    "    model_sample_strong_feature['x_085/x_081'] = data['x_085'] / (data['x_081'] + 1e-10)\n",
    "    model_sample_strong_feature['x_100/x_101'] = data['x_100'] / (data['x_101'] + 1e-10)\n",
    "    model_sample_strong_feature['x_102/x_103'] = data['x_102'] / (data['x_103'] + 1e-10)\n",
    "    model_sample_strong_feature['x_108/x_105'] = data['x_108'] / (data['x_105'] + 1e-10)\n",
    "    model_sample_strong_feature['x_104/x_102'] = data['x_104'] / (data['x_102'] + 1e-10)\n",
    "    model_sample_strong_feature['x_109/x_110'] = data['x_109'] / (data['x_110'] + 1e-10)\n",
    "    model_sample_strong_feature['x_111/x_109'] = data['x_111'] / (data['x_109'] + 1e-10)\n",
    "    model_sample_strong_feature['x_112/x_113'] = data['x_112'] / (data['x_113'] + 1e-10)\n",
    "    model_sample_strong_feature['x_114/x_112'] = data['x_114'] / (data['x_112'] + 1e-10)\n",
    "    model_sample_strong_feature['x_115/x_116'] = data['x_115'] / (data['x_116'] + 1e-10)\n",
    "    model_sample_strong_feature['x_117/x_115'] = data['x_117'] / (data['x_115'] + 1e-10) \n",
    "    model_sample_strong_feature['x_118/x_119'] = data['x_118'] / (data['x_119'] + 1e-10)\n",
    "    model_sample_strong_feature['x_120/x_118'] = data['x_120'] / (data['x_118'] + 1e-10) \n",
    "    model_sample_strong_feature['x_125/x_121'] = data['x_125'] / (data['x_121'] + 1e-10) \n",
    "    model_sample_strong_feature['x_128/x_129'] = data['x_128'] / (data['x_129'] + 1e-10)\n",
    "    model_sample_strong_feature['x_130/x_128'] = data['x_130'] / (data['x_128'] + 1e-10) \n",
    "    \n",
    "    \n",
    "    model_sample_strong_feature['x_133/x_134'] = data['x_133'] / (data['x_134'] + 1e-10)\n",
    "    model_sample_strong_feature['x_133/x_132'] = data['x_133'] / (data['x_132'] + 1e-10)\n",
    "    model_sample_strong_feature['x_134/x_132'] = data['x_134'] / (data['x_132'] + 1e-10)\n",
    "\n",
    "    model_sample_strong_feature['x_138/x_139'] = data['x_138'] / (data['x_139'] + 1e-10)\n",
    "    model_sample_strong_feature['x_138/x_137'] = data['x_138'] / (data['x_137'] + 1e-10)\n",
    "    model_sample_strong_feature['x_139/x_137'] = data['x_139'] / (data['x_137'] + 1e-10)\n",
    "\n",
    "    model_sample_strong_feature['x_143/x_142'] = data['x_143'] / (data['x_142'] + 1e-10)\n",
    "    model_sample_strong_feature['x_143/x_144'] = data['x_143'] / (data['x_144'] + 1e-10)\n",
    "    model_sample_strong_feature['x_144/x_142'] = data['x_144'] / (data['x_142'] + 1e-10)\n",
    "\n",
    "    model_sample_strong_feature['x_151/x_149'] = data['x_151'] / (data['x_149'] + 1e-10)\n",
    "    model_sample_strong_feature['x_152/x_149'] = data['x_152'] / (data['x_149'] + 1e-10)\n",
    "    model_sample_strong_feature['x_152/x_151'] = data['x_152'] / (data['x_151'] + 1e-10)\n",
    "    model_sample_strong_feature['x_154/x_153'] = data['x_154'] / (data['x_153'] + 1e-10)\n",
    "    model_sample_strong_feature['x_156/x_153'] = data['x_156'] / (data['x_153'] + 1e-10)\n",
    "    model_sample_strong_feature['x_157/x_153'] = data['x_157'] / (data['x_153'] + 1e-10)\n",
    "    model_sample_strong_feature['x_158/x_153'] = data['x_158'] / (data['x_153'] + 1e-10)\n",
    "    model_sample_strong_feature['x_159/x_153'] = data['x_159'] / (data['x_153'] + 1e-10)  \n",
    "    model_sample_strong_feature['x_154/x_155'] = data['x_154'] / (data['x_155'] + 1e-10)  \n",
    "\n",
    "\n",
    "    model_sample_strong_feature['x_164/x_162'] = data['x_164'] / (data['x_162'] + 1e-10)\n",
    "    model_sample_strong_feature['x_165/x_162'] = data['x_165'] / (data['x_162'] + 1e-10)\n",
    "    model_sample_strong_feature['x_165/x_164'] = data['x_165'] / (data['x_164'] + 1e-10)\n",
    "    model_sample_strong_feature['x_167/x_166'] = data['x_167'] / (data['x_166'] + 1e-10)\n",
    "    model_sample_strong_feature['x_169/x_166'] = data['x_169'] / (data['x_166'] + 1e-10)\n",
    "    model_sample_strong_feature['x_170/x_166'] = data['x_170'] / (data['x_166'] + 1e-10)\n",
    "    model_sample_strong_feature['x_171/x_166'] = data['x_171'] / (data['x_166'] + 1e-10)\n",
    "    model_sample_strong_feature['x_180/x_181'] = data['x_180'] / (data['x_181'] + 1e-10) \n",
    "    model_sample_strong_feature['x_167/x_168'] = data['x_167'] / (data['x_168'] + 1e-10) \n",
    "    model_sample_strong_feature['x_172/x_167'] = data['x_172'] / (data['x_167'] + 1e-10)  \n",
    "    \n",
    "    model_sample_strong_feature['x_177/x_175'] = data['x_177'] / (data['x_175'] + 1e-10)\n",
    "    model_sample_strong_feature['x_178/x_175'] = data['x_178'] / (data['x_175'] + 1e-10)\n",
    "    model_sample_strong_feature['x_178/x_177'] = data['x_178'] / (data['x_177'] + 1e-10)\n",
    "    model_sample_strong_feature['x_180/x_179'] = data['x_180'] / (data['x_179'] + 1e-10)\n",
    "    model_sample_strong_feature['x_182/x_179'] = data['x_182'] / (data['x_179'] + 1e-10)\n",
    "    model_sample_strong_feature['x_183/x_179'] = data['x_183'] / (data['x_179'] + 1e-10)\n",
    "    model_sample_strong_feature['x_184/x_179'] = data['x_184'] / (data['x_179'] + 1e-10)\n",
    "    model_sample_strong_feature['x_180/x_181'] = data['x_180'] / (data['x_181'] + 1e-10) \n",
    "    model_sample_strong_feature['x_185/x_180'] = data['x_185'] / (data['x_180'] + 1e-10)\n",
    " \n",
    "    model_sample_strong_feature['x_189/x_188'] = data['x_189'] / (data['x_188'] + 1e-10)\n",
    "    model_sample_strong_feature['x_191/x_190'] = data['x_191'] / (data['x_190'] + 1e-10)\n",
    "    model_sample_strong_feature['x_193/x_192'] = data['x_193'] / (data['x_192'] + 1e-10)\n",
    "    model_sample_strong_feature['x_195/x_194'] = data['x_195'] / (data['x_194'] + 1e-10)\n",
    "    model_sample_strong_feature['x_197/x_196'] = data['x_197'] / (data['x_196'] + 1e-10)\n",
    "    model_sample_strong_feature['x_199/x_198'] = data['x_199'] / (data['x_198'] + 1e-10)\n",
    "    model_sample_strong_feature['x_196/x_188'] = data['x_196'] / (data['x_188'] + 1e-10)\n",
    "    model_sample_strong_feature['x_192/x_188'] = data['x_192'] / (data['x_188'] + 1e-10)\n",
    "\n",
    "    \n",
    "    model_sample_strong_feature = model_sample_strong_feature.fillna(-999)\n",
    "    return model_sample_strong_feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sample_strong_feature_middle = get_features_middle(model_sample)\n",
    "model_sample_strong_feature_final = get_features_final(model_sample)\n",
    "model_sample_strong_feature_middle = model_sample_strong_feature_middle.fillna(-999)\n",
    "model_sample_strong_feature_final = model_sample_strong_feature_final.fillna(-999)\n",
    "model_sample_ = model_sample.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed is:  1\n",
      "5 fold no feature engineering\n",
      "TP:  312 / 390 all  870  accuracy:  0.6826347305389222  precision:  0.3586206896551724  recall:  0.8  F_score:  0.49523809523809514 0.49523809523809514\n",
      "TP:  288 / 390 all  732  accuracy:  0.7275449101796407  precision:  0.39344262295081966  recall:  0.7384615384615385  F_score:  0.5133689839572192 0.5133689839572192\n",
      "TP:  270 / 390 all  719  accuracy:  0.7160678642714571  precision:  0.37552155771905427  recall:  0.6923076923076923  F_score:  0.48692515779981965 0.48692515779981965\n",
      "TP:  277 / 390 all  739  accuracy:  0.7130738522954092  precision:  0.37483085250338294  recall:  0.7102564102564103  F_score:  0.4906997342781223 0.4906997342781223\n",
      "TP:  277 / 390 all  739  accuracy:  0.7130738522954092  precision:  0.37483085250338294  recall:  0.7102564102564103  F_score:  0.4906997342781223 0.4906997342781223\n",
      "TP:  284 / 390 all  749  accuracy:  0.7150698602794411  precision:  0.37917222963951935  recall:  0.7282051282051282  F_score:  0.49868305531167684 0.49868305531167684\n",
      "**************************************************\n",
      "5 fold feature engineering middle\n",
      "TP:  317 / 390 all  870  accuracy:  0.687624750499002  precision:  0.364367816091954  recall:  0.8128205128205128  F_score:  0.5031746031746032 0.5031746031746032\n",
      "TP:  293 / 390 all  780  accuracy:  0.7085828343313373  precision:  0.37564102564102564  recall:  0.7512820512820513  F_score:  0.5008547008547009 0.5008547008547009\n",
      "TP:  287 / 390 all  764  accuracy:  0.7105788423153693  precision:  0.3756544502617801  recall:  0.735897435897436  F_score:  0.4974003466204506 0.4974003466204506\n",
      "TP:  292 / 390 all  772  accuracy:  0.7115768463073853  precision:  0.37823834196891193  recall:  0.7487179487179487  F_score:  0.5025817555938038 0.5025817555938038\n",
      "TP:  292 / 390 all  774  accuracy:  0.7105788423153693  precision:  0.3772609819121447  recall:  0.7487179487179487  F_score:  0.5017182130584192 0.5017182130584192\n",
      "TP:  297 / 390 all  785  accuracy:  0.7100798403193613  precision:  0.378343949044586  recall:  0.7615384615384615  F_score:  0.505531914893617 0.505531914893617\n",
      "**************************************************\n",
      "5 fold feature engineering final\n",
      "TP:  316 / 390 all  867  accuracy:  0.68812375249501  precision:  0.3644752018454441  recall:  0.8102564102564103  F_score:  0.5027844073190135 0.5027844073190135\n",
      "TP:  285 / 390 all  756  accuracy:  0.7125748502994012  precision:  0.376984126984127  recall:  0.7307692307692307  F_score:  0.4973821989528795 0.4973821989528795\n",
      "TP:  283 / 390 all  738  accuracy:  0.719560878243513  precision:  0.38346883468834686  recall:  0.7256410256410256  F_score:  0.50177304964539 0.50177304964539\n",
      "TP:  288 / 390 all  751  accuracy:  0.7180638722554891  precision:  0.38348868175765644  recall:  0.7384615384615385  F_score:  0.5048203330411919 0.5048203330411919\n",
      "TP:  288 / 390 all  749  accuracy:  0.719061876247505  precision:  0.38451268357810414  recall:  0.7384615384615385  F_score:  0.5057067603160668 0.5057067603160668\n",
      "TP:  292 / 390 all  764  accuracy:  0.7155688622754491  precision:  0.38219895287958117  recall:  0.7487179487179487  F_score:  0.5060658578856152 0.5060658578856152\n",
      "**************************************************\n",
      "Fire!\n",
      "middle  and  original \n",
      "TP:  287 / 390 all  755  accuracy:  0.7150698602794411  precision:  0.3801324503311258  recall:  0.735897435897436  F_score:  0.5013100436681223 0.5013100436681223\n",
      "TP:  289 / 390 all  753  accuracy:  0.7180638722554891  precision:  0.3837981407702523  recall:  0.7410256410256411  F_score:  0.505686789151356 0.505686789151356\n",
      "final and  original \n",
      "TP:  291 / 390 all  752  accuracy:  0.720558882235529  precision:  0.386968085106383  recall:  0.7461538461538462  F_score:  0.5096322241681261 0.5096322241681261\n",
      "TP:  291 / 390 all  751  accuracy:  0.7210578842315369  precision:  0.38748335552596536  recall:  0.7461538461538462  F_score:  0.5100788781770377 0.5100788781770377\n",
      "final and  middle and original \n",
      "TP:  288 / 390 all  762  accuracy:  0.7125748502994012  precision:  0.3779527559055118  recall:  0.7384615384615385  F_score:  0.5 0.5\n",
      "TP:  288 / 390 all  763  accuracy:  0.7120758483033932  precision:  0.37745740498034075  recall:  0.7384615384615385  F_score:  0.4995663486556809 0.4995663486556809\n",
      "TP:  291 / 390 all  769  accuracy:  0.7120758483033932  precision:  0.3784135240572172  recall:  0.7461538461538462  F_score:  0.5021570319240725 0.5021570319240725\n",
      "TP:  294 / 390 all  779  accuracy:  0.7100798403193613  precision:  0.3774069319640565  recall:  0.7538461538461538  F_score:  0.5029940119760479 0.5029940119760479\n",
      "Random Seed is:  10\n",
      "5 fold no feature engineering\n",
      "TP:  309 / 427 all  834  accuracy:  0.6791417165668663  precision:  0.37050359712230213  recall:  0.7236533957845434  F_score:  0.49008723235527357 0.49008723235527357\n",
      "TP:  300 / 427 all  739  accuracy:  0.717564870259481  precision:  0.4059539918809202  recall:  0.702576112412178  F_score:  0.5145797598627787 0.5145797598627787\n",
      "TP:  300 / 427 all  721  accuracy:  0.7265469061876247  precision:  0.4160887656033287  recall:  0.702576112412178  F_score:  0.5226480836236934 0.5226480836236934\n",
      "TP:  305 / 427 all  736  accuracy:  0.7240518962075848  precision:  0.41440217391304346  recall:  0.7142857142857143  F_score:  0.524505588993981 0.524505588993981\n",
      "TP:  306 / 427 all  740  accuracy:  0.7230538922155688  precision:  0.4135135135135135  recall:  0.7166276346604216  F_score:  0.5244215938303343 0.5244215938303343\n",
      "TP:  307 / 427 all  748  accuracy:  0.7200598802395209  precision:  0.410427807486631  recall:  0.7189695550351288  F_score:  0.5225531914893617 0.5225531914893617\n",
      "**************************************************\n",
      "5 fold feature engineering middle\n",
      "TP:  315 / 427 all  848  accuracy:  0.6781437125748503  precision:  0.3714622641509434  recall:  0.7377049180327869  F_score:  0.4941176470588235 0.4941176470588235\n",
      "TP:  291 / 427 all  747  accuracy:  0.7045908183632734  precision:  0.3895582329317269  recall:  0.6814988290398126  F_score:  0.4957410562180579 0.4957410562180579\n",
      "TP:  294 / 427 all  742  accuracy:  0.7100798403193613  precision:  0.39622641509433965  recall:  0.6885245901639344  F_score:  0.502994011976048 0.502994011976048\n",
      "TP:  288 / 427 all  737  accuracy:  0.7065868263473054  precision:  0.39077340569877883  recall:  0.6744730679156908  F_score:  0.49484536082474234 0.49484536082474234\n",
      "TP:  290 / 427 all  738  accuracy:  0.7080838323353293  precision:  0.39295392953929537  recall:  0.6791569086651054  F_score:  0.4978540772532189 0.4978540772532189\n",
      "TP:  293 / 427 all  748  accuracy:  0.7060878243512974  precision:  0.3917112299465241  recall:  0.6861826697892272  F_score:  0.49872340425531914 0.49872340425531914\n",
      "**************************************************\n",
      "5 fold feature engineering final\n",
      "TP:  310 / 427 all  835  accuracy:  0.6796407185628742  precision:  0.3712574850299401  recall:  0.7259953161592506  F_score:  0.491283676703645 0.491283676703645\n",
      "TP:  293 / 427 all  741  accuracy:  0.7095808383233533  precision:  0.39541160593792174  recall:  0.6861826697892272  F_score:  0.5017123287671234 0.5017123287671234\n",
      "TP:  302 / 427 all  755  accuracy:  0.7115768463073853  precision:  0.4  recall:  0.7072599531615925  F_score:  0.5109983079526227 0.5109983079526227\n",
      "TP:  306 / 427 all  751  accuracy:  0.717564870259481  precision:  0.40745672436750996  recall:  0.7166276346604216  F_score:  0.5195246179966044 0.5195246179966044\n",
      "TP:  305 / 427 all  749  accuracy:  0.717564870259481  precision:  0.40720961281708945  recall:  0.7142857142857143  F_score:  0.5187074829931972 0.5187074829931972\n",
      "TP:  308 / 427 all  760  accuracy:  0.7150698602794411  precision:  0.4052631578947368  recall:  0.7213114754098361  F_score:  0.518955349620893 0.518955349620893\n",
      "**************************************************\n",
      "Fire!\n",
      "middle  and  original \n",
      "TP:  295 / 427 all  735  accuracy:  0.7145708582834331  precision:  0.4013605442176871  recall:  0.6908665105386417  F_score:  0.5077452667814114 0.5077452667814114\n",
      "TP:  296 / 427 all  736  accuracy:  0.7150698602794411  precision:  0.40217391304347827  recall:  0.6932084309133489  F_score:  0.5090283748925193 0.5090283748925193\n",
      "final and  original \n",
      "TP:  303 / 427 all  734  accuracy:  0.7230538922155688  precision:  0.4128065395095368  recall:  0.7096018735362998  F_score:  0.5219638242894058 0.5219638242894058\n",
      "TP:  304 / 427 all  738  accuracy:  0.7220558882235529  precision:  0.41192411924119243  recall:  0.711943793911007  F_score:  0.5218884120171674 0.5218884120171674\n",
      "final and  middle and original \n",
      "TP:  298 / 427 all  740  accuracy:  0.7150698602794411  precision:  0.4027027027027027  recall:  0.6978922716627635  F_score:  0.5107112253641817 0.5107112253641817\n",
      "TP:  296 / 427 all  739  accuracy:  0.7135728542914171  precision:  0.40054127198917455  recall:  0.6932084309133489  F_score:  0.5077186963979416 0.5077186963979416\n",
      "TP:  300 / 427 all  750  accuracy:  0.7120758483033932  precision:  0.4  recall:  0.702576112412178  F_score:  0.5097706032285472 0.5097706032285472\n",
      "TP:  301 / 427 all  757  accuracy:  0.7095808383233533  precision:  0.39762219286657857  recall:  0.7049180327868853  F_score:  0.5084459459459459 0.5084459459459459\n",
      "Random Seed is:  100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold no feature engineering\n",
      "TP:  281 / 386 all  814  accuracy:  0.6816367265469062  precision:  0.3452088452088452  recall:  0.727979274611399  F_score:  0.4683333333333333 0.4683333333333333\n",
      "TP:  262 / 386 all  692  accuracy:  0.7235528942115769  precision:  0.3786127167630058  recall:  0.6787564766839378  F_score:  0.48608534322820035 0.48608534322820035\n",
      "TP:  261 / 386 all  688  accuracy:  0.7245508982035929  precision:  0.3793604651162791  recall:  0.6761658031088082  F_score:  0.48603351955307256 0.48603351955307256\n",
      "TP:  265 / 386 all  690  accuracy:  0.7275449101796407  precision:  0.38405797101449274  recall:  0.6865284974093264  F_score:  0.4925650557620818 0.4925650557620818\n",
      "TP:  264 / 386 all  687  accuracy:  0.7280439121756487  precision:  0.38427947598253276  recall:  0.6839378238341969  F_score:  0.49207828518173347 0.49207828518173347\n",
      "TP:  264 / 386 all  700  accuracy:  0.7215568862275449  precision:  0.37714285714285717  recall:  0.6839378238341969  F_score:  0.4861878453038674 0.4861878453038674\n",
      "**************************************************\n",
      "5 fold feature engineering middle\n",
      "TP:  282 / 386 all  806  accuracy:  0.6866267465069861  precision:  0.34987593052109184  recall:  0.7305699481865285  F_score:  0.4731543624161075 0.4731543624161075\n",
      "TP:  272 / 386 all  721  accuracy:  0.719061876247505  precision:  0.37725381414701803  recall:  0.7046632124352331  F_score:  0.4914182475158085 0.4914182475158085\n",
      "TP:  274 / 386 all  723  accuracy:  0.7200598802395209  precision:  0.3789764868603043  recall:  0.7098445595854922  F_score:  0.4941388638412985 0.4941388638412985\n",
      "TP:  276 / 386 all  720  accuracy:  0.7235528942115769  precision:  0.38333333333333336  recall:  0.7150259067357513  F_score:  0.49909584086799275 0.49909584086799275\n",
      "TP:  276 / 386 all  718  accuracy:  0.7245508982035929  precision:  0.38440111420612816  recall:  0.7150259067357513  F_score:  0.5 0.5\n",
      "TP:  276 / 386 all  728  accuracy:  0.719560878243513  precision:  0.3791208791208791  recall:  0.7150259067357513  F_score:  0.4955116696588869 0.4955116696588869\n",
      "**************************************************\n",
      "5 fold feature engineering final\n",
      "TP:  284 / 386 all  813  accuracy:  0.685129740518962  precision:  0.34932349323493234  recall:  0.7357512953367875  F_score:  0.47372810675562965 0.47372810675562965\n",
      "TP:  261 / 386 all  713  accuracy:  0.7120758483033932  precision:  0.36605890603085556  recall:  0.6761658031088082  F_score:  0.47497725204731567 0.47497725204731567\n",
      "TP:  261 / 386 all  703  accuracy:  0.7170658682634731  precision:  0.3712660028449502  recall:  0.6761658031088082  F_score:  0.47933884297520657 0.47933884297520657\n",
      "TP:  267 / 386 all  714  accuracy:  0.717564870259481  precision:  0.3739495798319328  recall:  0.6917098445595855  F_score:  0.4854545454545454 0.4854545454545454\n",
      "TP:  265 / 386 all  716  accuracy:  0.7145708582834331  precision:  0.37011173184357543  recall:  0.6865284974093264  F_score:  0.4809437386569873 0.4809437386569873\n",
      "TP:  268 / 386 all  724  accuracy:  0.7135728542914171  precision:  0.3701657458563536  recall:  0.694300518134715  F_score:  0.48288288288288284 0.48288288288288284\n",
      "**************************************************\n",
      "Fire!\n",
      "middle  and  original \n",
      "TP:  266 / 386 all  705  accuracy:  0.7210578842315369  precision:  0.3773049645390071  recall:  0.689119170984456  F_score:  0.4876260311640696 0.4876260311640696\n",
      "TP:  267 / 386 all  707  accuracy:  0.7210578842315369  precision:  0.37765205091937765  recall:  0.6917098445595855  F_score:  0.48856358645928627 0.48856358645928627\n",
      "final and  original \n",
      "TP:  267 / 386 all  706  accuracy:  0.7215568862275449  precision:  0.3781869688385269  recall:  0.6917098445595855  F_score:  0.48901098901098905 0.48901098901098905\n",
      "TP:  267 / 386 all  705  accuracy:  0.7220558882235529  precision:  0.37872340425531914  recall:  0.6917098445595855  F_score:  0.4894592117323556 0.4894592117323556\n",
      "final and  middle and original \n",
      "TP:  268 / 386 all  706  accuracy:  0.7225548902195609  precision:  0.37960339943342775  recall:  0.694300518134715  F_score:  0.49084249084249076 0.49084249084249076\n",
      "TP:  266 / 386 all  705  accuracy:  0.7210578842315369  precision:  0.3773049645390071  recall:  0.689119170984456  F_score:  0.4876260311640696 0.4876260311640696\n",
      "TP:  270 / 386 all  717  accuracy:  0.719061876247505  precision:  0.37656903765690375  recall:  0.6994818652849741  F_score:  0.4895738893925657 0.4895738893925657\n",
      "TP:  272 / 386 all  724  accuracy:  0.717564870259481  precision:  0.3756906077348066  recall:  0.7046632124352331  F_score:  0.4900900900900901 0.4900900900900901\n",
      "Random Seed is:  1000\n",
      "5 fold no feature engineering\n",
      "TP:  296 / 396 all  776  accuracy:  0.7105788423153693  precision:  0.38144329896907214  recall:  0.7474747474747475  F_score:  0.5051194539249146 0.5051194539249146\n",
      "TP:  267 / 396 all  656  accuracy:  0.7415169660678643  precision:  0.4070121951219512  recall:  0.6742424242424242  F_score:  0.5076045627376427 0.5076045627376427\n",
      "TP:  264 / 396 all  661  accuracy:  0.7360279441117764  precision:  0.39939485627836613  recall:  0.6666666666666666  F_score:  0.49952696310312206 0.49952696310312206\n",
      "TP:  265 / 396 all  653  accuracy:  0.7410179640718563  precision:  0.4058192955589586  recall:  0.6691919191919192  F_score:  0.5052430886558626 0.5052430886558626\n",
      "TP:  265 / 396 all  654  accuracy:  0.7405189620758483  precision:  0.40519877675840976  recall:  0.6691919191919192  F_score:  0.5047619047619046 0.5047619047619046\n",
      "TP:  267 / 396 all  665  accuracy:  0.7370259481037924  precision:  0.40150375939849625  recall:  0.6742424242424242  F_score:  0.5032987747408106 0.5032987747408106\n",
      "**************************************************\n",
      "5 fold feature engineering middle\n",
      "TP:  298 / 396 all  795  accuracy:  0.7030938123752495  precision:  0.37484276729559746  recall:  0.7525252525252525  F_score:  0.5004198152812762 0.5004198152812762\n",
      "TP:  262 / 396 all  668  accuracy:  0.7305389221556886  precision:  0.39221556886227543  recall:  0.6616161616161617  F_score:  0.4924812030075188 0.4924812030075188\n",
      "TP:  264 / 396 all  676  accuracy:  0.7285429141716567  precision:  0.3905325443786982  recall:  0.6666666666666666  F_score:  0.4925373134328358 0.4925373134328358\n",
      "TP:  264 / 396 all  676  accuracy:  0.7285429141716567  precision:  0.3905325443786982  recall:  0.6666666666666666  F_score:  0.4925373134328358 0.4925373134328358\n",
      "TP:  262 / 396 all  675  accuracy:  0.7270459081836327  precision:  0.38814814814814813  recall:  0.6616161616161617  F_score:  0.4892623716153128 0.4892623716153128\n",
      "TP:  268 / 396 all  684  accuracy:  0.7285429141716567  precision:  0.391812865497076  recall:  0.6767676767676768  F_score:  0.49629629629629635 0.49629629629629635\n",
      "**************************************************\n",
      "5 fold feature engineering final\n",
      "TP:  298 / 396 all  807  accuracy:  0.6971057884231537  precision:  0.36926889714993805  recall:  0.7525252525252525  F_score:  0.4954280964256027 0.4954280964256027\n",
      "TP:  265 / 396 all  677  accuracy:  0.7290419161676647  precision:  0.3914327917282127  recall:  0.6691919191919192  F_score:  0.4939422180801491 0.4939422180801491\n",
      "TP:  261 / 396 all  665  accuracy:  0.7310379241516967  precision:  0.3924812030075188  recall:  0.6590909090909091  F_score:  0.49198868991517447 0.49198868991517447\n",
      "TP:  266 / 396 all  675  accuracy:  0.7310379241516967  precision:  0.3940740740740741  recall:  0.6717171717171717  F_score:  0.49673202614379086 0.49673202614379086\n",
      "TP:  267 / 396 all  674  accuracy:  0.7325349301397206  precision:  0.3961424332344214  recall:  0.6742424242424242  F_score:  0.4990654205607477 0.4990654205607477\n",
      "TP:  272 / 396 all  690  accuracy:  0.7295409181636726  precision:  0.39420289855072466  recall:  0.6868686868686869  F_score:  0.5009208103130756 0.5009208103130756\n",
      "**************************************************\n",
      "Fire!\n",
      "middle  and  original \n",
      "TP:  266 / 396 all  674  accuracy:  0.7315369261477046  precision:  0.39465875370919884  recall:  0.6717171717171717  F_score:  0.49719626168224307 0.49719626168224307\n",
      "TP:  265 / 396 all  671  accuracy:  0.7320359281437125  precision:  0.3949329359165425  recall:  0.6691919191919192  F_score:  0.4967197750702906 0.4967197750702906\n",
      "final and  original \n",
      "TP:  265 / 396 all  660  accuracy:  0.7375249500998003  precision:  0.4015151515151515  recall:  0.6691919191919192  F_score:  0.5018939393939394 0.5018939393939394\n",
      "TP:  263 / 396 all  657  accuracy:  0.7370259481037924  precision:  0.4003044140030441  recall:  0.6641414141414141  F_score:  0.49952516619183285 0.49952516619183285\n",
      "final and  middle and original \n",
      "TP:  267 / 396 all  672  accuracy:  0.7335329341317365  precision:  0.39732142857142855  recall:  0.6742424242424242  F_score:  0.5 0.5\n",
      "TP:  265 / 396 all  669  accuracy:  0.7330339321357285  precision:  0.3961136023916293  recall:  0.6691919191919192  F_score:  0.4976525821596244 0.4976525821596244\n",
      "TP:  268 / 396 all  677  accuracy:  0.7320359281437125  precision:  0.39586410635155095  recall:  0.6767676767676768  F_score:  0.49953401677539605 0.49953401677539605\n",
      "TP:  270 / 396 all  685  accuracy:  0.7300399201596807  precision:  0.39416058394160586  recall:  0.6818181818181818  F_score:  0.49953746530989823 0.49953746530989823\n"
     ]
    }
   ],
   "source": [
    "for rnd in [1,10,100,1000]:\n",
    "    print('Random Seed is: ',rnd)  \n",
    "    train_X,test_X, train_y, test_y = train_test_split(model_sample_strong_feature_final,label,test_size=0.2,random_state=rnd) \n",
    "    \n",
    "    train_X_orig = model_sample_.loc[train_X.index]\n",
    "    test_X_orig = model_sample_.loc[test_X.index]\n",
    "    train_X_middle = model_sample_strong_feature_middle.loc[train_X.index]\n",
    "    test_X_middle = model_sample_strong_feature_middle.loc[test_X.index]\n",
    "    \n",
    "    \n",
    "    print('5 fold no feature engineering')\n",
    "    pred_out_lgb, pred_out_gbdt, pred_out_rf = N_Fold_Predict(train_X_orig, train_y['y'].values, test_X_orig, cv_ = 3)\n",
    "    pred =pred_out_rf >= 0.215\n",
    "    get_score(pred, test_y['y'].values)\n",
    "    pred =pred_out_gbdt >= 0.215\n",
    "    get_score(pred, test_y['y'].values)\n",
    "    pred =pred_out_lgb >= 0.215\n",
    "    get_score(pred, test_y['y'].values)\n",
    "    pred =pred_out_lgb * 0.55 + 0.45 * pred_out_gbdt>= 0.215\n",
    "    get_score(pred, test_y['y'].values)\n",
    "    pred =pred_out_lgb * 0.5 + 0.5 * pred_out_gbdt>= 0.215\n",
    "    get_score(pred, test_y['y'].values)\n",
    "    pred =(pred_out_lgb * 0.5 + 0.5 * pred_out_gbdt) * 0.9 + 0.1 * pred_out_rf>= 0.215\n",
    "    get_score(pred, test_y['y'].values)\n",
    "    \n",
    "    print('*' * 50)\n",
    "    print('5 fold feature engineering middle')\n",
    "    pred_out_lgb_middle, pred_out_gbdt_middle, pred_out_rf_middle = N_Fold_Predict(train_X_middle,train_y['y'].values, test_X_middle, cv_ = 3)\n",
    "    pred = pred_out_rf_middle >= 0.215\n",
    "    get_score(pred, test_y['y'].values)\n",
    "    pred =pred_out_gbdt_middle >= 0.215\n",
    "    get_score(pred, test_y['y'].values)\n",
    "    pred =pred_out_lgb_middle >= 0.215\n",
    "    get_score(pred, test_y['y'].values)\n",
    "    \n",
    "    pred =pred_out_lgb_middle * 0.55 + 0.45 * pred_out_gbdt_middle>= 0.215\n",
    "    get_score(pred, test_y['y'].values)\n",
    "    pred =pred_out_lgb_middle * 0.5 + 0.5 * pred_out_gbdt_middle>= 0.215\n",
    "    get_score(pred, test_y['y'].values)\n",
    "    pred =(pred_out_lgb_middle * 0.5 + 0.5 * pred_out_gbdt_middle) * 0.9 + 0.1 * pred_out_rf_middle >= 0.215\n",
    "    get_score(pred, test_y['y'].values)\n",
    "     \n",
    "#     pred =(pred_out_lgb_middle * 0.5 + 0.5 * pred_out_gbdt_middle) * 0.9 + 0.05 * (pred_out_rf_middle + pred_out_rf)>= 0.215\n",
    "#     get_score(pred, test_y['y'].values)\n",
    "     \n",
    "    \n",
    "    print('*' * 50)\n",
    "    print('5 fold feature engineering final')\n",
    "    pred_out_lgb_final, pred_out_gbdt_final, pred_out_rf_final = N_Fold_Predict(train_X,train_y['y'].values, test_X, cv_ = 3)\n",
    "    pred =pred_out_rf_final >= 0.215\n",
    "    get_score(pred, test_y['y'].values)\n",
    "    pred =pred_out_gbdt_final >= 0.215\n",
    "    get_score(pred, test_y['y'].values)\n",
    "    pred =pred_out_lgb_final >= 0.215\n",
    "    get_score(pred, test_y['y'].values)\n",
    "    \n",
    "    pred =pred_out_lgb_final * 0.55 + 0.45 * pred_out_gbdt_final>= 0.215\n",
    "    get_score(pred, test_y['y'].values)\n",
    "    pred =pred_out_lgb_final * 0.5 + 0.5 * pred_out_gbdt_final>= 0.215\n",
    "    get_score(pred, test_y['y'].values)\n",
    "    pred =(pred_out_lgb_final * 0.5 + 0.5 * pred_out_gbdt_final) * 0.9 + 0.1 * pred_out_rf_final>= 0.215\n",
    "    get_score(pred, test_y['y'].values)\n",
    "    \n",
    "    print('*' * 50)\n",
    "     \n",
    "    print('Fire!')\n",
    "    print('middle  and  original ')\n",
    "    \n",
    "    pred =((pred_out_lgb_middle * 0.5 + pred_out_lgb * 0.5 )*0.55  + 0.45 * (pred_out_gbdt_middle * 0.5 + 0.5 * pred_out_gbdt))>= 0.215\n",
    "    get_score(pred, test_y['y'].values)\n",
    "    pred =((pred_out_lgb_middle * 0.5 + pred_out_lgb* 0.5 )*0.5  + 0.5 * (pred_out_gbdt_middle *0.5 + 0.5 * pred_out_gbdt ))>= 0.215\n",
    "    get_score(pred, test_y['y'].values) \n",
    "     \n",
    "    print('final and  original ')\n",
    "    pred =((pred_out_lgb_final * 0.5 + pred_out_lgb * 0.5 )*0.55  + 0.45 * (pred_out_gbdt_final * 0.5 + 0.5 * pred_out_gbdt))>= 0.215\n",
    "    get_score(pred, test_y['y'].values)\n",
    "    pred =((pred_out_lgb_final * 0.5 + pred_out_lgb* 0.5 )*0.5  + 0.5 * (pred_out_gbdt_final *0.5 + 0.5 * pred_out_gbdt ))>= 0.215\n",
    "    get_score(pred, test_y['y'].values) \n",
    "     \n",
    "    \n",
    "    print('final and  middle and original ')\n",
    "    pred =((pred_out_lgb_final * 0.3 + pred_out_lgb * 0.3 + 0.4 * pred_out_lgb_middle)*0.55  + 0.45 * (pred_out_gbdt_final * 0.3 + 0.3 * pred_out_gbdt + 0.4 * pred_out_gbdt_middle))>= 0.215\n",
    "    get_score(pred, test_y['y'].values)\n",
    "    pred =((pred_out_lgb_final * 1.0 /3 + pred_out_lgb* 1.0 /3 +  pred_out_lgb_middle* 1.0 /3)*0.5  + 0.5 * (pred_out_gbdt_final * 1.0 /3 +  1.0 /3 * pred_out_gbdt + 1.0 /3 * pred_out_gbdt_middle))>= 0.215\n",
    "    get_score(pred, test_y['y'].values) \n",
    "    \n",
    "    pred = 0.1 * (pred_out_rf_middle + pred_out_rf + pred_out_rf_final ) /3.0 + 0.9 * ((pred_out_lgb_final * 1.0 /3 + pred_out_lgb* 1.0 /3 +  pred_out_lgb_middle* 1.0 /3)*0.5  + 0.5 * (pred_out_gbdt_final * 1.0 /3 +  1.0 /3 * pred_out_gbdt + 1.0 /3 * pred_out_gbdt_middle))>= 0.215\n",
    "    get_score(pred, test_y['y'].values) \n",
    "    pred = 0.15 * (pred_out_rf_middle + pred_out_rf + pred_out_rf_final ) /3.0 + 0.85 * ((pred_out_lgb_final * 1.0 /3 + pred_out_lgb* 1.0 /3 +  pred_out_lgb_middle* 1.0 /3)*0.5  + 0.5 * (pred_out_gbdt_final * 1.0 /3 +  1.0 /3 * pred_out_gbdt + 1.0 /3 * pred_out_gbdt_middle))>= 0.215\n",
    "    get_score(pred, test_y['y'].values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
